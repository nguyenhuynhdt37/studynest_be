# app/services/user/tutor_chat_message.py
"""
TutorChatMessageService - X·ª≠ l√Ω chat messages.

ƒê·∫ßu v√†o:
- lesson_id: ID b√†i h·ªçc
- message: N·ªôi dung tin nh·∫Øn

T·∫°m th·ªùi ch·ªâ nh·∫≠n input v√† tr·∫£ v·ªÅ response m·∫´u ƒë·ªÉ test API.
"""

import uuid
from typing import Any, Dict, List, Optional

from fastapi import Depends, HTTPException, UploadFile
from sqlalchemy import and_, desc, or_, select, text
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.core.embedding import (
    EmbeddingService,
    get_embedding_service,
)
from app.db.models.database import (
    TutorChatImages,
    TutorChatMessages,
)
from app.db.sesson import get_session
from app.schemas.chat.user.tutor_chat import ChatImageSchema
from app.services.shares.google_driver import (
    GoogleDriveAsyncService,
    get_google_drive_service,
)
from app.services.shares.OCR_service import OCRService, get_ocr_service
from app.services.user.message_classifier import (
    MessageClassifierService,
    get_message_classifier_service,
)
from app.services.user.tutor_chat import TutorChatService, get_tutor_chat_service


class TutorChatMessageService:
    """Service x·ª≠ l√Ω chat messages."""

    def __init__(
        self,
        db: AsyncSession = Depends(get_session),
        thread_service: TutorChatService = Depends(get_tutor_chat_service),
        classifier_service: MessageClassifierService = Depends(
            get_message_classifier_service
        ),
        drive_service: GoogleDriveAsyncService = Depends(get_google_drive_service),
        ocr_service: OCRService = Depends(get_ocr_service),
        embedding_service: EmbeddingService = Depends(get_embedding_service),
    ):
        self.db = db
        self.thread_service = thread_service
        self.classifier_service = classifier_service
        self.drive_service = drive_service
        self.ocr_service = ocr_service
        self.embedding_service = embedding_service

    async def upload_and_ocr_images(
        self,
        user_id: uuid.UUID,
        files: List[UploadFile],
    ) -> List[Dict[str, Any]]:
        """
        Upload danh s√°ch ·∫£nh v√† OCR.
        Tr·∫£ v·ªÅ list metadata ƒë·ªÉ client g·ª≠i k√®m message.
        """
        results = []
        for file in files:
            # Validate
            if not file.content_type.startswith("image/"):
                continue

            content = await file.read()
            file_size = len(content)
            filename = f"{uuid.uuid4()}_{file.filename}"

            # 1. Upload Google Drive
            upload_res = await self.drive_service.upload_file(
                path_parts=["tutor_chat", str(user_id)],
                file_name=filename,
                content=content,
                mime_type=file.content_type,
            )

            # Share public
            await self.drive_service.create_share_link(upload_res["id"])
            url = upload_res["webViewLink"]

            # 2. OCR
            try:
                ocr_text = self.ocr_service.extract_text_from_image(content)
            except Exception:
                ocr_text = ""

            results.append(
                {
                    "url": url,
                    "file_size": file_size,
                    "mime_type": file.content_type,
                    "ocr_text": ocr_text,
                    "drive_id": upload_res["id"],
                }
            )
        return results

    async def send_message(
        self,
        user_id: uuid.UUID,
        lesson_id: uuid.UUID,
        message: str,
        thread_id: Optional[uuid.UUID] = None,
        images: Optional[List[ChatImageSchema]] = None,
    ) -> Dict[str, Any]:
        """
        G·ª≠i tin nh·∫Øn chat.

        Args:
            user_id: ID ng∆∞·ªùi d√πng
            lesson_id: ID b√†i h·ªçc
            message: N·ªôi dung tin nh·∫Øn
            thread_id: ID thread (optional, n·∫øu kh√¥ng c√≥ s·∫Ω d√πng active thread)
            images: List[ChatImageDTO] (Optional)

        Returns:
            {
                "user_message": {...},
                "assistant_message": {...},
                "thread": {...},
            }
        """
        # 1. L·∫•y ho·∫∑c t·∫°o active thread
        if thread_id:
            # Verify thread belongs to user
            thread_data = await self.thread_service.get_thread_by_id(user_id, thread_id)
            if not thread_data:
                raise HTTPException(status_code=404, detail="Thread not found")
        else:
            # L·∫•y ho·∫∑c t·∫°o active thread cho lesson
            result = await self.thread_service.get_or_create_active_thread(
                user_id=user_id,
                lesson_id=lesson_id,
            )
            thread_data = result["thread"]
            thread_id = uuid.UUID(thread_data["id"])

        # 1.5 Fetch last 4 messages for context (with images)
        history_result = await self.db.execute(
            select(TutorChatMessages)
            .options(selectinload(TutorChatMessages.tutor_chat_images))
            .where(TutorChatMessages.thread_id == thread_id)
            .order_by(desc(TutorChatMessages.created_at))
            .limit(4)
        )
        history_messages = history_result.scalars().all()
        # Reverse to chronological order for context
        history_messages = list(reversed(history_messages))

        # Process context for LLM/Preprocessing
        context = []
        msg_count = len(history_messages)
        for i, msg in enumerate(history_messages):
            # Combine content with OCR from images
            combined_content = msg.content
            if msg.tutor_chat_images:
                img_texts = [
                    f"[IMG {idx+1}] {img.ocr_text}"
                    for idx, img in enumerate(msg.tutor_chat_images)
                    if img.ocr_text
                ]
                if img_texts:
                    combined_content += "\n\n" + "\n C√¢u h·ªèi th√™m t·ª´ ·∫£nh: ".join(
                        img_texts
                    )

            # Mark last 2 messages as latest
            is_latest = i >= msg_count - 2
            context.append(
                {
                    "role": msg.role,
                    "content": combined_content,
                    "sources": msg.sources,  # Keep sources separate
                    "is_latest": is_latest,
                }
            )

        # Get latest sources from history
        latest_sources = next(
            (msg.sources for msg in reversed(history_messages) if msg.sources), None
        )

        # 2. Save User Message to DB immediately
        user_msg = TutorChatMessages(
            thread_id=thread_id,
            user_id=user_id,
            role="user",
            content=message,
            sources=[],  # User messages typically have no sources
            # images=images  # TODO: Handle images properly if your model has this field
        )
        self.db.add(user_msg)
        await self.db.flush()  # Flush to get user_msg.id
        await self.db.refresh(user_msg)

        # 3. Save Images (if any)
        image_context = ""
        if images:
            image_context_parts = []
            for idx, img in enumerate(images, 1):
                # Save to DB
                chat_image = TutorChatImages(
                    message_id=user_msg.id,
                    user_id=user_id,
                    url=img.url,
                    file_size=img.file_size or 0,
                    mime_type=img.mime_type,
                    ocr_text=img.ocr_text or "",
                )
                self.db.add(chat_image)

                # Append to context
                if img.ocr_text:
                    image_context_parts.append(f"H√¨nh ·∫£nh {idx}: {img.ocr_text}")

            await self.db.flush()  # Save images

            if image_context_parts:
                image_context = "\nDanh s√°ch c√¢u h·ªèi t·ª´ h√¨nh ·∫£nh:\n" + "\n".join(
                    image_context_parts
                )

        # 4. Combine with main message for AI processing
        full_message = message
        if image_context:
            full_message += f"\n\n{image_context}"

        # 5. Classify intent
        has_prev_context = bool(latest_sources)  # If we have sources from previous chat

        # Format history for classifier (List[Dict])
        chat_history_dicts = [
            {"role": msg.role, "content": msg.content} for msg in history_messages
        ]

        classify_result = await self.classifier_service.classify_message(
            message=full_message,
            chat_history=chat_history_dicts,
            has_prev_context=has_prev_context,
        )
        mode = classify_result["mode"]
        print(f"DEBUG: Mode={mode}, has_prev_context={has_prev_context}")

        # 6. Execute based on Mode
        sources = []
        response_content = ""

        if mode == "NO_SEARCH":
            # Case 1: Small talk / No context needed
            sources = []

        elif mode == "REUSE":
            # Case 2: Reuse previous context
            sources = latest_sources or []

        else:  # SEARCH
            # Case 3: RAG Search
            print("DEBUG: Executing RAG Search...")
            thread_scope = thread_data.get("scope", "lesson")
            sources = await self._rag_search(
                query=full_message,
                lesson_id=lesson_id,
                scope=thread_scope,
                user_id=user_id,
            )
            print(f"DEBUG: Found {len(sources)} sources")

        # Build prompt v√† g·ªçi LLM
        prompt = self._build_prompt(
            user_message=full_message,
            context=context,
            sources=sources,
            mode=mode,
        )

        # G·ªçi LLM
        print("DEBUG: Calling LLM...")
        llm_response = await self._call_llm(prompt)
        print("DEBUG: LLM response received")

        # Parse JSON response
        import json

        try:
            result = json.loads(llm_response)
        except json.JSONDecodeError:
            # Fallback n·∫øu LLM kh√¥ng tr·∫£ ƒë√∫ng JSON
            result = {
                "title": "C√¢u h·ªèi m·ªõi",
                "content": llm_response,
                "sources_used": [],
            }

        # Chu·∫©n h√≥a k·∫øt qu·∫£
        bot_title = result.get("title", "C√¢u h·ªèi m·ªõi")
        bot_content = result.get("content", "")
        sources_used = result.get("sources_used", [])

        # 5. L∆∞u tin nh·∫Øn c·ªßa bot v√†o DB
        assistant_msg = TutorChatMessages(
            thread_id=thread_id,
            user_id=user_id,
            role="assistant",
            content=bot_content,
            sources=sources_used,  # L∆∞u sources ƒë√£ d√πng
        )
        self.db.add(assistant_msg)
        await self.db.flush()
        await self.db.refresh(assistant_msg)

        # 6. C·∫≠p nh·∫≠t title c·ªßa thread (n·∫øu ch∆∞a c√≥ ho·∫∑c l√† tin ƒë·∫ßu ti√™n)
        if thread_data.get("title") in [None, "", "Cu·ªôc tr√≤ chuy·ªán m·ªõi"]:
            await self.thread_service.update_thread(
                user_id=user_id,
                thread_id=thread_id,
                title=bot_title[:100],  # Gi·ªõi h·∫°n 100 k√Ω t·ª±
            )

        # Commit transaction
        await self.db.commit()

        # Return c√¢u tr·∫£ l·ªùi theo format chu·∫©n c·ªßa b·∫£ng TutorChatMessages
        return {
            "id": str(assistant_msg.id),
            "thread_id": str(assistant_msg.thread_id),
            "user_id": str(assistant_msg.user_id),
            "role": assistant_msg.role,
            "content": assistant_msg.content,
            "sources": assistant_msg.sources,
            "created_at": (
                assistant_msg.created_at.isoformat()
                if assistant_msg.created_at
                else None
            ),
            "images": [],  # Bot kh√¥ng c√≥ images
        }

    async def get_messages(
        self,
        user_id: uuid.UUID,
        thread_id: uuid.UUID,
        limit: int = 20,
        cursor_next: str = None,
    ) -> Dict[str, Any]:
        """
        L·∫•y danh s√°ch tin nh·∫Øn c·ªßa thread.
        Pagination: cursor-based (created_at).
        """
        from app.db.models.database import TutorChatMessages

        # 1. Base query
        stmt = (
            select(TutorChatMessages)
            .where(
                TutorChatMessages.thread_id == thread_id,
                TutorChatMessages.user_id == user_id,
            )
            .options(selectinload(TutorChatMessages.tutor_chat_images))
            .order_by(
                TutorChatMessages.created_at.desc(),
                TutorChatMessages.role.asc(),  # Assistant ('a') before User ('u') in DESC list
            )
        )

        # 2. Apply cursor
        if cursor_next:
            try:
                # cursor_next l√† ID c·ªßa message cu·ªëi c√πng l·∫ßn tr∆∞·ªõc
                # Ta c·∫ßn t√¨m created_at c·ªßa message ƒë√≥ ƒë·ªÉ filter
                cursor_msg = await self.db.get(
                    TutorChatMessages, uuid.UUID(cursor_next)
                )
                if cursor_msg:
                    # Cursor condition for: created_at DESC, role ASC
                    # We want rows "after" the cursor in the sort order.
                    # Since created_at is DESC, "after" means smaller time.
                    # If times are equal, we check role (ASC).
                    # "After" in ASC means larger role.
                    stmt = stmt.where(
                        or_(
                            TutorChatMessages.created_at < cursor_msg.created_at,
                            and_(
                                TutorChatMessages.created_at == cursor_msg.created_at,
                                TutorChatMessages.role > cursor_msg.role,
                            ),
                        )
                    )
            except Exception:
                pass  # Invalid cursor, ignore

        # 3. Limit (l·∫•y th·ª´a 1 ƒë·ªÉ check has_more)
        stmt = stmt.limit(limit + 1)

        # 4. Execute
        result = await self.db.execute(stmt)
        # S·ª≠ d·ª•ng unique() ƒë·ªÉ tr√°nh duplicates khi join (d√π selectinload handle r·ªìi nh∆∞ng unique() cho an to√†n v·ªõi scalars)
        messages = result.scalars().unique().all()

        # 5. Process pagination
        has_more = len(messages) > limit
        if has_more:
            messages = messages[:limit]
            next_cursor = str(messages[-1].id)
        else:
            if messages:
                next_cursor = str(messages[-1].id)
            else:
                next_cursor = None

        # 6. Format response
        results = []
        for msg in reversed(messages):
            results.append(
                {
                    "id": str(msg.id),
                    "thread_id": str(msg.thread_id),
                    "user_id": str(msg.user_id),
                    "role": msg.role,
                    "content": msg.content,
                    "sources": msg.sources,
                    "created_at": (
                        msg.created_at.isoformat() if msg.created_at else None
                    ),
                    "images": [
                        {
                            "id": str(img.id),
                            "url": img.url,
                            "file_size": img.file_size,
                            "mime_type": img.mime_type,
                            "ocr_text": img.ocr_text,
                            "created_at": (
                                img.created_at.isoformat() if img.created_at else None
                            ),
                        }
                        for img in msg.tutor_chat_images
                    ],
                }
            )

        return {
            "messages": results,
            "cursor_next": next_cursor if has_more else None,
            "has_more": has_more,
        }

    async def _rag_search(
        self,
        query: str,
        lesson_id: uuid.UUID,
        scope: str = "lesson",  # 'lesson' | 'section' | 'course'
        user_id: uuid.UUID = None,  # ƒê·ªÉ l·∫•y code hi·ªán t·∫°i c·ªßa h·ªçc vi√™n
    ) -> List[Dict[str, Any]]:
        """
        T√¨m ki·∫øm t√†i li·ªáu li√™n quan c√¢u h·ªèi.
        - Video: D√πng embedding search
        - Quiz/Code: L·∫•y to√†n b·ªô n·ªôi dung
        """
        if not query:
            return []

        results = []

        # 1. Check lesson type
        from app.db.models.database import LessonCodes, LessonQuizzes, Lessons

        lesson = await self.db.get(Lessons, lesson_id)
        if not lesson:
            return []

        lesson_type = lesson.lesson_type

        # 2. X·ª≠ l√Ω theo lo·∫°i lesson
        if lesson_type == "quiz":
            # L·∫•y to√†n b·ªô quiz questions c·ªßa lesson
            quizzes = await self.db.execute(
                select(LessonQuizzes)
                .options(selectinload(LessonQuizzes.lesson_quiz_options))
                .where(LessonQuizzes.lesson_id == lesson_id)
            )
            for q_idx, quiz in enumerate(quizzes.scalars().all(), 1):
                options_text = "\n".join(
                    [
                        f"  - {opt.text_} {'(ƒê√°p √°n ƒë√∫ng)' if opt.is_correct else ''}"
                        for opt in quiz.lesson_quiz_options
                    ]
                )
                content = f"C√¢u {q_idx}: {quiz.question}\nƒê√°p √°n:\n{options_text}"
                if quiz.explanation:
                    content += f"\nGi·∫£i th√≠ch: {quiz.explanation}"

                results.append(
                    {
                        "source_type": "quiz",
                        "similarity": 1.0,  # Direct match
                        "chunk_id": str(quiz.id),
                        "lesson_id": str(lesson_id),
                        "lesson_title": lesson.title,
                        "chunk_index": q_idx,  # D√πng s·ªë c√¢u l√†m chunk_index
                        "content": content,
                    }
                )

        elif lesson_type == "code":
            # L·∫•y to√†n b·ªô code exercises c·ªßa lesson

            codes = await self.db.execute(
                select(LessonCodes)
                .options(
                    selectinload(LessonCodes.lesson_code_files),
                    selectinload(LessonCodes.lesson_code_testcases),
                )
                .where(LessonCodes.lesson_id == lesson_id)
            )
            for code in codes.scalars().all():
                content = f"""=== B√ÄI T·∫¨P L·∫¨P TR√åNH ===
                Ti√™u ƒë·ªÅ: {code.title}
                M√¥ t·∫£: {code.description or 'Kh√¥ng c√≥ m√¥ t·∫£'}
                ƒê·ªô kh√≥: {code.difficulty}
                Gi·ªõi h·∫°n: {code.time_limit}s | Memory: {code.memory_limit // 1000000}MB

                """
                # Ph√¢n lo·∫°i files theo role
                starter_files = [
                    f for f in code.lesson_code_files if f.role == "starter"
                ]
                solution_files = [
                    f for f in code.lesson_code_files if f.role == "solution"
                ]

                # Th√™m starter code (code khung cho h·ªçc vi√™n)
                if starter_files:
                    content += "--- CODE KH·ªûI ƒê·∫¶U (Starter) ---\n"
                    content += "(Code m·∫´u h·ªçc vi√™n c·∫ßn ho√†n thi·ªán)\n"
                    for f in starter_files:
                        main_mark = " [MAIN]" if f.is_main else ""
                        content += f"\nüìÑ File: {f.filename}{main_mark}\n```\n{f.content}\n```\n"

                # Th√™m solution code (l·ªùi gi·∫£i chu·∫©n)
                if solution_files:
                    content += "\n--- CODE M·∫™U (Solution) ---\n"
                    content += "(ƒê√¢y l√† l·ªùi gi·∫£i chu·∫©n c·ªßa gi·∫£ng vi√™n)\n"
                    for f in solution_files:
                        main_mark = " [MAIN]" if f.is_main else ""
                        content += f"\nüìÑ File: {f.filename}{main_mark}\n```\n{f.content}\n```\n"

                # Th√™m code hi·ªán t·∫°i c·ªßa h·ªçc vi√™n (n·∫øu c√≥)
                if user_id:
                    user_files = [
                        f
                        for f in code.lesson_code_files
                        if f.role == "user" and f.user_id == user_id
                    ]
                    if user_files:
                        content += "\n--- CODE HI·ªÜN T·∫†I C·ª¶A H·ªåC VI√äN ---\n"
                        content += "(Code h·ªçc vi√™n ƒëang vi·∫øt, c√≥ th·ªÉ c·∫ßn h·ªó tr·ª£)\n"
                        for f in user_files:
                            main_mark = " [MAIN]" if f.is_main else ""
                            status = "‚úÖ PASS" if f.is_pass else "‚ùå CH∆ØA PASS"
                            content += f"\nüìÑ File: {f.filename}{main_mark} - {status}\n```\n{f.content}\n```\n"

                # Th√™m testcases (ch·ªâ sample cases)
                sample_cases = [tc for tc in code.lesson_code_testcases if tc.is_sample]
                hidden_cases = [
                    tc for tc in code.lesson_code_testcases if not tc.is_sample
                ]

                if sample_cases:
                    content += "\n--- TEST CASES M·∫™U ---\n"
                    for i, tc in enumerate(sample_cases, 1):
                        content += f"Test {i}:\n  Input: {tc.input}\n  Expected: {tc.expected_output}\n"

                if hidden_cases:
                    content += f"\n(+ {len(hidden_cases)} hidden test cases)\n"

                results.append(
                    {
                        "source_type": "code",
                        "similarity": 1.0,
                        "chunk_id": str(code.id),
                        "lesson_id": str(lesson_id),
                        "lesson_title": lesson.title,
                        "chunk_index": 0,
                        "content": content,
                    }
                )

        else:
            # Video/Article: D√πng embedding search nh∆∞ c≈©
            embedding = await self.embedding_service.embed_google_normalized(query)
            embedding_str = str(embedding)

            stmt = text(
                """
                SELECT * FROM public.rag_search_scope(:lesson_id, :scope, :embedding)
            """
            )

            result = await self.db.execute(
                stmt,
                {"lesson_id": lesson_id, "scope": scope, "embedding": embedding_str},
            )

            for row in result.fetchall():
                item = {
                    "source_type": row.source_type,
                    "similarity": row.similarity,
                    "chunk_id": str(row.chunk_id) if row.chunk_id else None,
                    "lesson_id": str(row.lesson_id) if row.lesson_id else None,
                    "lesson_title": row.lesson_title,
                    "chunk_index": row.chunk_index,
                    "content": row.content,
                }

                if row.source_type == "resource":
                    item["resource_id"] = (
                        str(row.resource_id) if row.resource_id else None
                    )
                    item["resource_title"] = row.resource_title
                    item["resource_url"] = row.resource_url

                results.append(item)

        # 3. B·ªï sung resource chunks n·∫øu c√≥ (cho quiz/code lessons)
        # Video/article ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω trong rag_search_scope
        if lesson_type in ["quiz", "code"]:
            # Ki·ªÉm tra xem lesson c√≥ resources kh√¥ng
            from app.db.models.database import LessonResources

            has_resources = await self.db.execute(
                select(LessonResources.id)
                .where(LessonResources.lesson_id == lesson_id)
                .limit(1)
            )

            if has_resources.scalar_one_or_none():
                # T√¨m resource chunks b·∫±ng embedding
                embedding = await self.embedding_service.embed_google_normalized(query)
                embedding_str = str(embedding)

                resource_stmt = text(
                    """
                    SELECT 
                        rc.id as chunk_id,
                        rc.lesson_id,
                        l.title as lesson_title,
                        rc.chunk_index,
                        rc.content,
                        r.id as resource_id,
                        r.title as resource_title,
                        r.url as resource_url,
                        1 - (rc.embedding <=> :embedding::vector) as similarity
                    FROM public.resource_chunks rc
                    JOIN public.lesson_resources r ON rc.resource_id = r.id
                    JOIN public.lessons l ON rc.lesson_id = l.id
                    WHERE rc.lesson_id = :lesson_id
                    AND 1 - (rc.embedding <=> :embedding::vector) >= 0.7
                    ORDER BY similarity DESC
                    LIMIT 2
                """
                )

                resource_result = await self.db.execute(
                    resource_stmt, {"lesson_id": lesson_id, "embedding": embedding_str}
                )

                for row in resource_result.fetchall():
                    results.append(
                        {
                            "source_type": "resource",
                            "similarity": row.similarity,
                            "chunk_id": str(row.chunk_id),
                            "lesson_id": str(row.lesson_id),
                            "lesson_title": row.lesson_title,
                            "chunk_index": row.chunk_index,
                            "content": row.content,
                            "resource_id": str(row.resource_id),
                            "resource_title": row.resource_title,
                            "resource_url": row.resource_url,
                        }
                    )

        return results

    def _build_prompt(
        self,
        user_message: str,
        context: List[Dict[str, Any]],
        sources: List[Dict[str, Any]],
        mode: str,
    ) -> str:
        """
        X√¢y d·ª±ng prompt cho LLM d·ª±a tr√™n context, sources v√† mode.
        """
        prompt = """# VAI TR√í
            B·∫°n l√† **Tutor AI** - tr·ª£ l√Ω h·ªçc t·∫≠p th√¥ng minh c·ªßa n·ªÅn t·∫£ng StudyNest. 
            Nhi·ªám v·ª• c·ªßa b·∫°n l√† h·ªó tr·ª£ h·ªçc vi√™n hi·ªÉu b√†i h·ªçc, gi·∫£i ƒë√°p th·∫Øc m·∫Øc v√† h∆∞·ªõng d·∫´n th·ª±c h√†nh.

            # NGUY√äN T·∫ÆC TR·∫¢ L·ªúI
            1. **Ch√≠nh x√°c**: Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p. N·∫øu kh√¥ng c√≥ th√¥ng tin, n√≥i r√µ.
            2. **D·ªÖ hi·ªÉu**: Gi·∫£i th√≠ch t·ª´ng b∆∞·ªõc, s·ª≠ d·ª•ng v√≠ d·ª• c·ª• th·ªÉ v√† minh h·ªça khi c·∫ßn.
            3. **Th·ª±c ti·ªÖn**: ƒê∆∞a ra code m·∫´u, b√†i t·∫≠p th·ª±c h√†nh khi ph√π h·ª£p.
            4. **Khuy·∫øn kh√≠ch**: ƒê·ªông vi√™n h·ªçc vi√™n, g·ª£i √Ω h∆∞·ªõng ƒëi ti·∫øp theo.
            5. **Ng√¥n ng·ªØ**: Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán nh∆∞ng chuy√™n nghi·ªáp.

            # ƒê·ªäNH D·∫†NG OUTPUT
            - S·ª≠ d·ª•ng Markdown ƒë·ªÉ format c√¢u tr·∫£ l·ªùi.
            - Code block v·ªõi syntax highlighting khi c·∫ßn.
            - Bullet points cho danh s√°ch.
            - Bold/italic ƒë·ªÉ nh·∫•n m·∫°nh ƒëi·ªÉm quan tr·ªçng.
            """

        # Add context t·ª´ l·ªãch s·ª≠ chat
        if context:
            prompt += "\n---\n# L·ªäCH S·ª¨ H·ªòI THO·∫†I\n"
            for msg in context[-4:]:
                role = "üë§ H·ªçc vi√™n" if msg["role"] == "user" else "ü§ñ Tutor AI"
                content = msg["content"][:600]
                prompt += f"\n{role}:\n{content}\n"

        # Add sources t·ª´ RAG
        if sources and mode in ["SEARCH", "REUSE"]:
            prompt += """
            ---
            # T√ÄI LI·ªÜU THAM KH·∫¢O
            D∆∞·ªõi ƒë√¢y l√† n·ªôi dung li√™n quan t·ª´ b√†i h·ªçc. H√£y s·ª≠ d·ª•ng ƒë·ªÉ tr·∫£ l·ªùi:

            """
            for i, src in enumerate(sources, 1):
                # Gi·ªØ nguy√™n source_type g·ªëc, ch·ªâ ƒë·ªïi "lesson" ‚Üí "video"
                raw_source_type = src.get("source_type", "video")
                source_type = (
                    "video" if raw_source_type == "lesson" else raw_source_type
                )
                chunk_id = src.get("chunk_id", "")
                lesson_id = src.get("lesson_id", "")
                lesson_title = src.get("lesson_title", "")
                chunk_index = src.get("chunk_index", 0)
                similarity = src.get("similarity", 0)
                content = src.get("content", "")

                if source_type == "resource":
                    resource_id = src.get("resource_id", "")
                    resource_title = src.get("resource_title", "T√†i li·ªáu")
                    resource_url = src.get("resource_url", "")
                    prompt += f"""### [{i}] üìÑ T√†i li·ªáu: {resource_title}
            - chunk_id: {chunk_id}
            - resource_id: {resource_id}
            - resource_title: {resource_title}
            - resource_url: {resource_url}
            - B√†i h·ªçc: {lesson_title}
            - ƒê·ªô li√™n quan: {similarity:.0%}
            ```
            {content}
            ```

            """
                else:
                    prompt += f"""### [{i}] üé¨ B√†i h·ªçc: {lesson_title}
            - chunk_id: {chunk_id}
            - lesson_id: {lesson_id}
            - lesson_title: {lesson_title}
            - chunk_index: {chunk_index}
            - ƒê·ªô li√™n quan: {similarity:.0%}
            ```
            {content}
            ```

            """

        # H∆∞·ªõng d·∫´n ƒë·∫∑c bi·ªát theo mode
        if mode == "NO_SEARCH":
            prompt += """
            ---
            # CH√ö √ù
            ƒê√¢y l√† c√¢u h·ªèi chung, kh√¥ng c·∫ßn tham kh·∫£o t√†i li·ªáu c·ª• th·ªÉ.
            """

        # Add user message
        prompt += f"""
            ---
            # C√ÇU H·ªéI HI·ªÜN T·∫†I
            üë§ **H·ªçc vi√™n h·ªèi:**
            {user_message}

            ---
            # Y√äU C·∫¶U OUTPUT
            Tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng JSON v·ªõi format sau:
            ```json
            {{
                "title": "Ti√™u ƒë·ªÅ ng·∫Øn g·ªçn t√≥m t·∫Øt c√¢u h·ªèi (t·ªëi ƒëa 50 k√Ω t·ª±)",
                "content": "N·ªôi dung tr·∫£ l·ªùi chi ti·∫øt, s·ª≠ d·ª•ng Markdown formatting",
                "sources_used": [
                    {{
                        "index": 1,
                        "source_type": "video" ,
                        "chunk_id": "uuid c·ªßa chunk",
                        "lesson_id": "uuid c·ªßa lesson",
                        "lesson_title": "T√™n b√†i h·ªçc",
                        "summary": "T√≥m t·∫Øt ng·∫Øn g·ªçn n·ªôi dung ƒëo·∫°n n√†y (20-30 t·ª´)",
                        "similarity": 1,
                        "chunk_index": 0 | None,
                        "timestamp_seconds": 0 | None,
                    }},
                    {{
                        "index": 2,
                        "source_type": "resource",
                        "chunk_id": "uuid c·ªßa chunk",
                        "resource_id": "uuid c·ªßa resource",
                        "resource_title": "T√™n t√†i li·ªáu",
                        "summary": "T√≥m t·∫Øt ng·∫Øn g·ªçn n·ªôi dung ƒëo·∫°n n√†y (20-30 t·ª´)",
                        "resource_url": "URL t√†i li·ªáu",
                        "similarity": 0.75,
                    }},
                    {{
                        "index": 3,
                        "source_type": "code",
                        "lesson_id": "uuid c·ªßa lesson",
                        "code_id": "uuid c·ªßa code",
                        "lesson_title": "T√™n b√†i h·ªçc",
                        "summary": "T√≥m t·∫Øt ng·∫Øn g·ªçn n·ªôi dung ƒëo·∫°n n√†y (20-30 t·ª´)",
                        "code_content": "N·ªôi dung code",
                        "similarity": 0.75,
                    }},
                    {{
                        "index": 4,
                        "source_type": "quiz",
                        "lesson_id": "uuid c·ªßa lesson",
                        "quiz_id": "uuid c·ªßa quiz",
                        "quizz_option_id": "uuid c·ªßa option",
                        "lesson_title": "T√™n b√†i h·ªçc",
                        "summary": "T√≥m t·∫Øt ng·∫Øn g·ªçn n·ªôi dung ƒëo·∫°n n√†y (20-30 t·ª´)",
                        "similarity": 0.73,
                        "quizz_option_title": "T√™n option",
                        "quizz_option_content": "N·ªôi dung option",
                    }}
                ]
            }}
            ```
            
            L∆∞u √Ω quan tr·ªçng:
            - "title": Ti√™u ƒë·ªÅ ng·∫Øn g·ªçn, s√∫c t√≠ch m√¥ t·∫£ n·ªôi dung c√¢u h·ªèi
            - "content": Tr·∫£ l·ªùi ƒë·∫ßy ƒë·ªß, d·ªÖ hi·ªÉu, c√≥ v√≠ d·ª• minh h·ªça
            - "sources_used": Ch·ªâ li·ªát k√™ c√°c t√†i li·ªáu TH·ª∞C S·ª∞ ƒë∆∞·ª£c d√πng ƒë·ªÉ tr·∫£ l·ªùi
              + "summary": T√≥m t·∫Øt n·ªôi dung ch√≠nh c·ªßa ƒëo·∫°n n√†y (v√≠ d·ª•: "Gi·ªõi thi·ªáu JavaScript v√† l·ªãch s·ª≠ ra ƒë·ªùi")
              + V·ªõi source_type="video": L·∫•y timestamp_seconds t·ª´ n·ªôi dung (v√≠ d·ª•: `00:15` = 15, `01:20` = 80)
              + V·ªõi source_type="code": Kh√¥ng c·∫ßn timestamp_seconds
              + V·ªõi source_type="quiz": Kh√¥ng c·∫ßn timestamp_seconds
              + Copy ch√≠nh x√°c c√°c gi√° tr·ªã chunk_id, lesson_id, resource_id t·ª´ t√†i li·ªáu tham kh·∫£o
              + S·∫Øp x·∫øp theo index gi·∫£m d·∫ßn
            """

        return prompt

    async def _call_llm(
        self,
        prompt: str,
    ) -> str:
        """
        G·ªçi LLM service ƒë·ªÉ sinh c√¢u tr·∫£ l·ªùi JSON.
        """
        from app.core.llm import LLMService

        llm = LLMService()
        response = await llm.call_model(
            prompt=prompt,
            mime_type="application/json",
            temperature=0.7,
            max_output_tokens=4000,
        )
        return response


def get_tutor_chat_message_service(
    db: AsyncSession = Depends(get_session),
    thread_service: TutorChatService = Depends(get_tutor_chat_service),
    classifier_service: MessageClassifierService = Depends(
        get_message_classifier_service
    ),
    drive_service: GoogleDriveAsyncService = Depends(get_google_drive_service),
    ocr_service: OCRService = Depends(get_ocr_service),
    embedding_service: EmbeddingService = Depends(get_embedding_service),
) -> TutorChatMessageService:
    return TutorChatMessageService(
        db=db,
        thread_service=thread_service,
        classifier_service=classifier_service,
        drive_service=drive_service,
        ocr_service=ocr_service,
        embedding_service=embedding_service,
    )
