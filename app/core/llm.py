import asyncio
import logging

import google.generativeai as genai
from google.api_core.exceptions import (
    InvalidArgument,
    PermissionDenied,
    ResourceExhausted,
)

from app.core.settings import settings

logger = logging.getLogger(__name__)


class LLMService:
    """D·ªãch v·ª• g·ªçi Gemini LLM (chu·∫©n API m·ªõi, ·ªïn ƒë·ªãnh, retry + fallback)."""

    def __init__(self) -> None:
        genai.configure(api_key=settings.GOOGLE_API_KEY_CHAT)

        # === Model M·ªöI CH√çNH X√ÅC NH·∫§T CHO generate_content ===
        self.primary_model = "models/gemini-2.0-flash"
        self.fallback_model = "models/gemini-2.0-pro"

    async def call_model(
        self,
        prompt: str,
        retries: int = 3,
        mime_type: str = "application/json",
        temperature: float = 0.5,
        max_output_tokens: int = 8000,
    ) -> str:

        async def _safe_call(model_name: str) -> str:
            def _sync_call():
                model = genai.GenerativeModel(model_name)

                response = model.generate_content(
                    prompt,
                    generation_config={
                        "response_mime_type": mime_type,
                        "temperature": temperature,
                        "max_output_tokens": max_output_tokens,
                    },
                )

                # SDK m·ªõi: d√πng .text kh√¥ng c√≤n ch·∫Øc ch·∫Øn ‚Üí d√πng .candidates
                try:
                    text = response.text.strip()
                except Exception:
                    text = response.candidates[0].content.parts[0].text.strip()

                if not text:
                    return "‚ö†Ô∏è M√¥ h√¨nh kh√¥ng sinh ƒë∆∞·ª£c n·ªôi dung."

                return text

            return await asyncio.to_thread(_sync_call)

        # ===== G·ªçi model ch√≠nh (retry) =====
        for attempt in range(1, retries + 1):
            try:
                return await _safe_call(self.primary_model)

            except ResourceExhausted:
                wait_time = 2 * attempt
                logger.warning(
                    f"‚ö†Ô∏è Quota b·ªã gi·ªõi h·∫°n (attempt {attempt}/{retries}), ƒë·ª£i {wait_time}s..."
                )
                await asyncio.sleep(wait_time)

            except PermissionDenied:
                logger.error("üö´ API key sai ho·∫∑c ch∆∞a b·∫≠t billing.")
                return "üö´ API key kh√¥ng h·ª£p l·ªá ho·∫∑c ch∆∞a b·∫≠t billing."

            except InvalidArgument as e:
                logger.error(f"‚ùå L·ªói tham s·ªë: {e}")
                return "‚ö†Ô∏è Prompt kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë·ªãnh d·∫°ng sai."

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è L·ªói t·∫°m th·ªùi t·ª´ Gemini: {e}")
                await asyncio.sleep(2)

        # ===== Fallback sang model m·∫°nh h∆°n =====
        try:
            logger.info("üîÅ ƒêang th·ª≠ g·ªçi model d·ª± ph√≤ng (gemini-2.0-pro)...")
            return await _safe_call(self.fallback_model)

        except Exception as e:
            logger.error(f"‚ùå Fallback c≈©ng fail: {e}")
            return "‚ùå M√°y ch·ªß AI ƒëang qu√° t·∫£i, th·ª≠ l·∫°i sau."
