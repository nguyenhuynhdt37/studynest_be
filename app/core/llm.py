import asyncio
import logging

import google.generativeai as genai
from google.api_core.exceptions import (
    InvalidArgument,
    PermissionDenied,
    ResourceExhausted,
)

from app.core.settings import settings

logger = logging.getLogger(__name__)


class LLMService:
    """D·ªãch v·ª• g·ªçi Gemini LLM (·ªïn ƒë·ªãnh, c√≥ fallback & retry)."""

    def __init__(self) -> None:
        genai.configure(api_key=settings.GOOGLE_API_KEY_CHAT)
        self.primary_model = "gemini-2.5-flash"
        self.fallback_model = "gemini-1.5-flash"

    async def call_model(self, prompt: str, retries: int = 3) -> str:
        """
        G·ªçi m√¥ h√¨nh Gemini ƒë·ªÉ sinh n·ªôi dung.
        - C√≥ retry t·ª± ƒë·ªông n·∫øu g·∫∑p l·ªói t·∫°m th·ªùi (rate limit, quota).
        - T·ª± ƒë·ªông fallback sang model nh·∫π h∆°n n·∫øu model ch√≠nh l·ªói n·∫∑ng.
        """

        async def _safe_call(model_name: str) -> str:
            def _sync_call():
                model = genai.GenerativeModel(model_name)
                response = model.generate_content(prompt)

                # X·ª≠ l√Ω ph·∫£n h·ªìi kh√¥ng h·ª£p l·ªá
                if not response or not getattr(response, "text", None):
                    return "‚ö†Ô∏è M√¥ h√¨nh kh√¥ng th·ªÉ t·∫°o ph·∫£n h·ªìi cho y√™u c·∫ßu n√†y."
                text = response.text.strip()
                # Ki·ªÉm tra ƒë·ªô r·ªóng / v√¥ nghƒ©a
                if len(text) < 10 or "I‚Äôm sorry" in text or "Xin l·ªói" in text:
                    return "‚ö†Ô∏è M√¥ h√¨nh kh√¥ng th·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c cho n·ªôi dung n√†y."
                return text

            return await asyncio.to_thread(_sync_call)

        # ==== G·ªçi model ch√≠nh k√®m retry ====
        for attempt in range(1, retries + 1):
            try:
                return await _safe_call(self.primary_model)
            except ResourceExhausted:  # Quota exceeded / rate limit
                wait_time = 2 * attempt
                logger.warning(
                    f"‚ö†Ô∏è Quota b·ªã gi·ªõi h·∫°n (attempt {attempt}/{retries}), ƒë·ª£i {wait_time}s..."
                )
                await asyncio.sleep(wait_time)
            except PermissionDenied:
                logger.error("üö´ API key kh√¥ng h·ª£p l·ªá ho·∫∑c ch∆∞a b·∫≠t billing.")
                return "üö´ API key kh√¥ng h·ª£p l·ªá ho·∫∑c ch∆∞a b·∫≠t billing cho d·ª± √°n Google Cloud."
            except InvalidArgument as e:
                logger.error(f"‚ùå L·ªói tham s·ªë prompt: {e}")
                return "‚ö†Ô∏è L·ªói c√∫ ph√°p prompt ho·∫∑c d·ªØ li·ªáu ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá."
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è L·ªói t·∫°m khi g·ªçi Gemini: {e}")
                await asyncio.sleep(2)

        # ==== N·∫øu model ch√≠nh th·∫•t b·∫°i ‚Üí th·ª≠ fallback model ====
        try:
            logger.info("üîÅ ƒêang th·ª≠ g·ªçi model d·ª± ph√≤ng gemini-1.5-flash ...")
            return await _safe_call(self.fallback_model)
        except Exception as e:
            logger.error(f"‚ùå C·∫£ 2 model Gemini ƒë·ªÅu th·∫•t b·∫°i: {e}")
            return "‚ùå H·ªá th·ªëng t·∫°m th·ªùi kh√¥ng th·ªÉ t·∫°o n·ªôi dung. Vui l√≤ng th·ª≠ l·∫°i sau."
