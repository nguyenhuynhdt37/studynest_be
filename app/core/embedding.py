# app/core/embedding.py
import asyncio
import mimetypes
import uuid
from email.quoprimime import unquote
from math import exp
from urllib.parse import unquote

import google.generativeai as genai
import httpx
import numpy as np
import tiktoken
from fastapi import HTTPException
from loguru import logger
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.llm import LLMService
from app.core.settings import settings
from app.db.models.database import User, UserEmbeddingHistory
from app.db.sesson import AsyncSessionLocal
from app.libs.formats.datetime import now as get_now


class EmbeddingService:
    BASE_URL = "https://generativelanguage.googleapis.com/v1beta/models"

    def __init__(self):
        genai.configure(api_key=settings.GOOGLE_API_KEY)
        self.llm_service = LLMService()
        self._enc = tiktoken.get_encoding("cl100k_base")
        self.EMBED_MODEL = "models/gemini-embedding-001"
        self.EMBED_DIM = 1536
        self.API_KEY = settings.GOOGLE_API_KEY

    async def embed_google_normalized(self, text: str) -> list[float]:
        """Sinh embedding Google Gemini, Ã©p chiá»u vÃ  chuáº©n hÃ³a vector."""
        if not text or not text.strip():
            return [0.0] * self.EMBED_DIM

        def _sync_embed():
            try:
                resp = genai.embed_content(
                    model=self.EMBED_MODEL,
                    content=text.strip(),
                    task_type="retrieval_document",
                    output_dimensionality=self.EMBED_DIM,
                )
                vector = np.array(resp["embedding"], dtype=np.float32)
                norm = np.linalg.norm(vector)
                if norm == 0:
                    return vector.tolist()
                # Chuáº©n hÃ³a L2 Ä‘á»ƒ DB lÆ°u Ä‘á»“ng nháº¥t
                normalized = (vector / norm).tolist()
                # Äáº£m báº£o Ä‘Ãºng chiá»u (cÃ³ lib Google Ä‘Ã´i khi tráº£ thiáº¿u)
                if len(normalized) != self.EMBED_DIM:
                    normalized += [0.0] * (self.EMBED_DIM - len(normalized))
                return normalized
            except Exception as e:
                print(f"âŒ Lá»—i khi embedding: {e}")
                return [0.0] * self.EMBED_DIM

        return await asyncio.to_thread(_sync_embed)

    # ========== GEMINI 2.5 FLASH ==========
    async def extract_video_context_from_url(self, url_sharelink: str) -> str:
        """PhÃ¢n tÃ­ch ná»™i dung video YouTube cÃ´ng khai báº±ng Gemini 2.5 Flash."""
        try:
            url = unquote(url_sharelink.strip('"'))

            text_prompt = """
            Báº¡n lÃ  **trá»£ lÃ½ AI chuyÃªn phÃ¢n tÃ­ch video há»c táº­p**, Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tá»‘i Æ°u hÃ³a dá»¯ liá»‡u cho há»‡ thá»‘ng RAG (Retrieval-Augmented Generation).

            HÃ£y xem video táº¡i liÃªn káº¿t sau vÃ  xuáº¥t ra **báº£n tÃ³m táº¯t chi tiáº¿t dÆ°á»›i dáº¡ng Markdown**, vá»›i cáº¥u trÃºc rÃµ rÃ ng, dá»… láº­p chá»‰ má»¥c (index) vÃ  dá»… tÃ¡ch Ä‘oáº¡n cho embedding.

            ## YÃªu cáº§u xuáº¥t káº¿t quáº£
            - Ghi rÃµ **má»‘c thá»i gian (hh:mm:ss)** cho tá»«ng Ä‘oáº¡n quan trá»ng (vÃ­ dá»¥: `0:45 - Giáº£i thÃ­ch khÃ¡i niá»‡m Measure`).
            - Liá»‡t kÃª **tÃªn chÆ°Æ¡ng hoáº·c ná»™i dung chÃ­nh**.
            - TrÃ¬nh bÃ y **cÃ¡c Ã½ quan trá»ng theo thá»© tá»± thá»i gian**.
            - MÃ´ táº£ **hÃ nh Ä‘á»™ng hoáº·c kiáº¿n thá»©c cá»‘t lÃµi** mÃ  giáº£ng viÃªn truyá»n Ä‘áº¡t.
            - NÃªu **chá»§ Ä‘á» chÃ­nh** vÃ  **má»¥c tiÃªu khÃ³a há»c**.
            - TÃ³m táº¯t **cÃ¡c kiáº¿n thá»©c hoáº·c ká»¹ nÄƒng Ä‘Æ°á»£c truyá»n Ä‘áº¡t**, bao gá»“m cáº£ thuáº­t ngá»¯ ká»¹ thuáº­t vÃ  vÃ­ dá»¥ minh há»a.
            - XÃ¡c Ä‘á»‹nh **Ä‘á»‘i tÆ°á»£ng há»c phÃ¹ há»£p** (ngÆ°á»i má»›i, trung cáº¥p, nÃ¢ng cao).
            - MÃ´ táº£ **cáº¥u trÃºc video** (pháº§n má»Ÿ Ä‘áº§u, lÃ½ thuyáº¿t, demo, thá»±c hÃ nh, tá»•ng káº¿t) náº¿u cÃ³ thá»ƒ suy luáº­n.
            - NgÃ´n ngá»¯ Ä‘áº§u ra giá»¯ nguyÃªn **ngÃ´n ngá»¯ gá»‘c cá»§a video**.

            ## Má»¥c tiÃªu xá»­ lÃ½
            - GiÃºp há»‡ thá»‘ng RAG cÃ³ thá»ƒ truy xuáº¥t chÃ­nh xÃ¡c ná»™i dung theo má»‘c thá»i gian.
            - Äáº£m báº£o má»—i Ä‘oáº¡n ná»™i dung cÃ³ **ngá»¯ cáº£nh Ä‘á»™c láº­p** vÃ  Ä‘á»§ chi tiáº¿t Ä‘á»ƒ sinh embedding vector hiá»‡u quáº£.
            - TrÃ¡nh vÄƒn phong quáº£ng cÃ¡o hay diá»…n giáº£i lan man â€” chá»‰ táº­p trung vÃ o **ná»™i dung giáº£ng dáº¡y vÃ  kiáº¿n thá»©c há»c táº­p.**

            ## Giá»›i háº¡n Ä‘áº§u ra
            - Náº¿u khÃ´ng truy cáº­p Ä‘Æ°á»£c video, hÃ£y **táº¡o báº£n mÃ´ táº£ dá»±a trÃªn metadata, tiÃªu Ä‘á», hoáº·c ná»™i dung cÃ³ thá»ƒ suy luáº­n.**
            ## Chá»‰ tráº£ vá» ná»™i dung, khÃ´ng giáº£i thÃ­ch gÃ¬ thÃªm.
            """

            payload = {
                "model": "gemini-2.5-flash",
                "contents": [
                    {
                        "parts": [
                            {"text": text_prompt},
                            {"file_data": {"file_uri": url}},
                        ]
                    }
                ],
            }

            # âœ… KhÃ´ng dÃ¹ng Authorization Bearer, chá»‰ truyá»n API key qua query param
            async with httpx.AsyncClient(timeout=600) as client:
                res = await client.post(
                    f"{self.BASE_URL}/gemini-2.5-flash:generateContent?key={self.API_KEY}",
                    headers={"Content-Type": "application/json"},
                    json=payload,
                )
                res.raise_for_status()
                data = res.json()  # báº¡n quÃªn dÃ²ng nÃ y

            # ðŸ” TrÃ­ch text tráº£ vá»
            text = (
                data.get("candidates", [{}])[0]
                .get("content", {})
                .get("parts", [{}])[0]
                .get("text", "")
            )

            return text or "âš ï¸ KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« Gemini."

        except httpx.HTTPStatusError as e:
            raise HTTPException(
                500,
                f"Gemini API lá»—i: {e.response.status_code} â†’ {e.response.text}",
            )
        except Exception as e:
            raise HTTPException(500, f"Lá»—i khi phÃ¢n tÃ­ch video: {e}")

    # ========== TOKENIZER ==========
    def estimate_tokens(self, text: str) -> int:
        if not text:
            return 0
        try:
            return len(self._enc.encode(text))
        except Exception:
            return len(text.split())

    def guess_mime_type(self, url: str) -> str:
        mime, _ = mimetypes.guess_type(url)
        return mime or "video/mp4"

    def split_text_by_tokens(
        self,
        text: str,
        chunk_size: int = 1000,
        overlap: int = 100,
    ):
        """
        Chia vÄƒn báº£n theo token, cÃ³ chá»“ng láº¥n overlap Ä‘á»ƒ giá»¯ ngá»¯ cáº£nh giá»¯a cÃ¡c Ä‘oáº¡n.
        - chunk_size: sá»‘ token tá»‘i Ä‘a cho má»—i chunk
        - overlap: sá»‘ token trÃ¹ng láº·p giá»¯a hai chunk liÃªn tiáº¿p
        """
        import tiktoken

        # 1ï¸âƒ£ Chuáº©n hÃ³a giÃ¡ trá»‹ overlap (phÃ²ng lá»—i)
        if overlap >= chunk_size:
            overlap = max(0, chunk_size // 5)  # overlap khÃ´ng thá»ƒ lá»›n hÆ¡n chunk_size

        enc = tiktoken.get_encoding("cl100k_base")
        tokens = enc.encode(text)
        total_tokens = len(tokens)

        chunks = []
        step = chunk_size - overlap

        # 2ï¸âƒ£ Chia theo bÆ°á»›c, Ä‘áº£m báº£o khÃ´ng dÆ° token cuá»‘i
        for i in range(0, total_tokens, step):
            end = min(i + chunk_size, total_tokens)
            chunk_tokens = tokens[i:end]
            chunk_text = enc.decode(chunk_tokens)
            chunks.append(chunk_text)

            if end >= total_tokens:
                break

        return chunks

    from typing import List

    def chunk_text(self, text: str, size: int = 700, overlap: int = 100) -> List[str]:
        """TÃ¡ch vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n cÃ³ Ä‘á»™ dÃ i cá»‘ Ä‘á»‹nh (theo token giáº£ láº­p, táº¡m báº±ng tá»«)."""
        words = text.split()
        chunks = []
        step = size - overlap
        for i in range(0, len(words), step):
            chunk = " ".join(words[i : i + size])
            chunks.append(chunk)
        return chunks

    # ========== ADAPTIVE USER EMBEDDING ==========
    async def update_user_embedding_adaptive(
        self,
        user_id: uuid.UUID,
        new_embedding: list[float] | None,
        interaction_type: str = "wishlist",
        course_id: uuid.UUID | None = None,
    ):
        async with AsyncSessionLocal() as db:
            user = await db.get(User, user_id)
            if not user:
                return

            # Náº¿u bá» yÃªu thÃ­ch â†’ tÃ­nh láº¡i
            if new_embedding is None:
                updated_vector = await self.recompute_user_embedding(
                    db, user_id, exclude_course_id=course_id
                )
                user.preferences_embedding = updated_vector
                user.preferences_embedding_date_updated_at = get_now()
                return

            strength = {
                "wishlist": 0.5,
                "start": 0.7,
                "complete": 1.0,
                "review": 1.2,
            }.get(interaction_type, 0.6)

            if (
                user.preferences_embedding is None
                or len(user.preferences_embedding) == 0
            ):
                old_vec = np.zeros(3072)
            else:
                old_vec = np.array(user.preferences_embedding)

            new_vec = np.array(new_embedding)
            days_since = (
                get_now() - (user.preferences_embedding_date_updated_at or get_now())
            ).days

            sim = np.dot(old_vec, new_vec) / (
                np.linalg.norm(old_vec) * np.linalg.norm(new_vec) + 1e-9
            )
            sim = np.clip(sim, 0.0, 1.0)

            base_lambda = 0.004
            lambda_ = (
                base_lambda * (1 + min(days_since / 60, 2.0) + (1 - sim) * 2) * strength
            )

            decay = exp(-lambda_ * days_since)
            updated = (old_vec * decay + new_vec) / (1 + decay)

            user.preferences_embedding = updated.tolist()
            user.preferences_embedding_date_updated_at = get_now()

            db.add(
                UserEmbeddingHistory(
                    user_id=user_id,
                    course_id=course_id,
                    embedding=new_embedding,
                    interaction_type=interaction_type,
                    lambda_=lambda_,
                    similarity=sim,
                    decay=decay,
                )
            )

            print(
                f"[Embedding âœ…] user={user.id} | type={interaction_type} | Î»={lambda_:.5f} | sim={sim:.2f}"
            )
            await db.commit()

    async def recompute_user_embedding(
        self,
        db: AsyncSession,
        user_id: uuid.UUID,
        exclude_course_id: uuid.UUID | None = None,
    ) -> list[float]:
        result = await db.scalars(
            select(UserEmbeddingHistory)
            .where(UserEmbeddingHistory.user_id == user_id)
            .order_by(UserEmbeddingHistory.created_at.asc())
        )
        history = result.all()

        if not history:
            return np.zeros(3072).tolist()

        vec = np.zeros(3072)
        last_time = history[0].created_at

        for h in history:
            if (
                exclude_course_id
                and h.course_id == exclude_course_id
                and h.interaction_type == "wishlist"
            ):
                continue

            days = (h.created_at - last_time).days
            decay = exp(-h.lambda_ * days)
            vec = (vec * decay + np.array(h.embedding)) / (1 + decay)
            last_time = h.created_at

        return vec.tolist()


# ============================================================
# âš¡ Singleton Provider cho FastAPI (dÃ¹ng @Depends)
# ============================================================

_embedding_service: EmbeddingService | None = None


async def get_embedding_service() -> EmbeddingService:
    global _embedding_service
    if _embedding_service is None:
        logger.info("ðŸš€ Khá»Ÿi táº¡o EmbeddingService láº§n Ä‘áº§u.")
        _embedding_service = EmbeddingService()
    return _embedding_service
